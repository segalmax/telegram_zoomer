# ðŸ§  AI Translation System

## ðŸŽ¯ Core Function
Transform news â†’ RIGHT-BIDLO Russian slang + inject semantic links to related posts

## ðŸ”§ Prompting Technique

### Prompt Architecture
```
[ROLE] â†’ RIGHT-BIDLO cynical analyst  
[TASK] â†’ Translate + add semantic links
[STYLE] â†’ Cynical but not hysterical, focus on motives
[LENGTH] â†’ Max 800 chars including links
[LINKING] â†’ Convert key phrases to [text](URL) format
[MEMORY] â†’ Previous translations for consistency
```

### Key Prompt Elements ([`app/translator.py:45`](../app/translator.py#L45))
1. **Role Definition** â†’ "Smart cynic who understands power mechanics"
2. **Length Constraints** â†’ Strict 1-3 paragraphs, 800 char limit
3. **Style Requirements** â†’ Variety in language, avoid formulaic patterns
4. **Link Instructions** â†’ 2-4 word phrases max, semantic not literal matching

### Anti-Patterns Engineered Out
- âŒ "ÐÑƒ Ñ‡Ñ‚Ð¾, Ñ‚Ð¾Ð²Ð°Ñ€Ð¸Ñ‰Ð¸..." repetitive openings
- âŒ >800 character bloated responses  
- âŒ Formulaic "ÐšÐ»Ð°ÑÑÐ¸Ñ‡ÐµÑÐºÐ°Ñ..." patterns
- âŒ Long phrase links that break flow

## ðŸ§  Memory Integration Architecture

### Memory Lifecycle
```mermaid
graph LR
    MSG[New Message] --> EMBED[Generate Embedding]
    EMBED --> SEARCH[Similarity Search k=10]
    SEARCH --> RANK[Recency + Similarity Ranking]
    RANK --> CONTEXT[Inject into Prompt]
    CONTEXT --> TRANSLATE[Claude Translation]
    TRANSLATE --> SAVE[Store New Memory]
```

### Memory Query Strategy ([`app/vector_store.py:140`](../app/vector_store.py#L140))
```python
# Semantic search with recency weighting
memories = recall(source_text, k=10)  # Fetch 10 best matches
context = build_memory_context(memories)  # Format for prompt
translation = translate_with_context(text, context)
```

### Memory Context Format
```
Previous translations for consistency:
1. ðŸ‡®ðŸ‡· Iran increases uranium enrichment â†’ https://t.me/chan/123
2. ðŸš Military operation in Gaza â†’ https://t.me/chan/124
...
```

## ðŸ”— Linking Mechanism

### How Links Are Generated ([`app/translator.py:70`](../app/translator.py#L70))
1. **Extract phrases** from translated text (2-4 words)
2. **Match semantically** against memory database  
3. **Convert to markdown** `[phrase](message_url)`
4. **Embed in translation** maintaining readability

### Link Selection Logic
- **Semantic similarity** > literal word matching
- **Destination URLs** point to translated posts (not source)
- **Phrase extraction** prioritizes military/political/geographic terms
- **Deduplication** ensures one link per phrase

### Example Output
```markdown
**Ð¨ÐµÑÑ‚ÑŒ Ð°Ð¼ÐµÑ€Ð¸ÐºÐ°Ð½ÑÐºÐ¸Ñ… "Ð½ÐµÐ²Ð¸Ð´Ð¸Ð¼Ð¾Ðº" [Ð²Ð·ÑÐ»Ð¸ ÐºÑƒÑ€Ñ Ð½Ð° Ð˜Ñ€Ð°Ð½](https://t.me/chan/123)**

[ÐŸÐ¾ÐºÐ° Ð¸Ð·Ñ€Ð°Ð¸Ð»ÑŒÑ‚ÑÐ½Ðµ](https://t.me/chan/124) Ð¼ÐµÑ‚Ð¾Ð´Ð¸Ñ‡Ð½Ð¾ ÑƒÑ‚ÑŽÐ¶Ð¸Ð»Ð¸ ÐÐµÑ‚Ð°Ð½Ñ†...
```

## ðŸŽ›ï¸ Configuration

### Memory Tuning
- `TM_RECENCY_WEIGHT=0.3` â†’ Balance similarity vs. freshness  
- `k=10` â†’ Number of memories retrieved
- `similarity_threshold=0.5` â†’ Minimum match quality

### Translation Controls  
- `temperature=0.85` â†’ Creative but consistent output
- `max_tokens=1000` â†’ Prevent runaway responses
- `model=claude-sonnet-4-20250514` â†’ Latest Claude version

## ðŸ” Critical Integration Points

### Memory â†’ Prompt Flow
```python
# 1. Query similar translations
memory = recall_tm(source_text, k=10)

# 2. Build context block  
context = memory_block(memory)

# 3. Inject into system prompt
prompt = make_linking_prompt(memory)

# 4. Single API call for translation + linking
result = claude.translate_and_link(source_text, prompt)
```

### Success Metrics
- **Memory effectiveness**: >0.7 avg similarity score
- **Link relevance**: Semantic matching over keyword matching
- **Style consistency**: Variation without formulaic patterns 